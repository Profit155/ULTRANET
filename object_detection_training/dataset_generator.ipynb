{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file is responsible for generating an object detection dataset from \"core material\" given to it in specified folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from skimage.transform import swirl\n",
    "from skimage import img_as_ubyte\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an ULTRA-IMPORTANT list that holds which folder will be converted to what class (by idx)\n",
    "# the class is later used to find the highest priority target (eg idx 5 is higher prioritty than idx 4)\n",
    "folder_class_priority = [\"filth\",\n",
    "                         \"stray\",\n",
    "                         \"schism\",\n",
    "                         \"drone\",\n",
    "                         \"soldier\",\n",
    "                         \"streetcleaner\",\n",
    "                         \"malicious_face\",\n",
    "                         \"cerberus\",\n",
    "                         \"swordsmachine\",\n",
    "                         \"mannequin\",\n",
    "                         \"gutterman\",\n",
    "                         \"virtue\",\n",
    "                         \"stalker\",\n",
    "                         \"sentry\",\n",
    "                         \"idol\",\n",
    "                         \"guttertank\",\n",
    "                         \"mindflayer\",\n",
    "                         \"insurrectionist\",\n",
    "                         \"ferryman\",\n",
    "                         \"hideous_mass\",\n",
    "                         \"red_sphere\",\n",
    "                         \"blue_sphere\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# material to create dataset with\n",
    "backgrounds_path = fr\".\\dataset_materials\\backgrounds\"\n",
    "objects_path = fr\".\\dataset_materials\\objects\"\n",
    "obstructions_path = fr\".\\dataset_materials\\obstructions\"\n",
    "\n",
    "# where to output the dataset (will automatically create folder structure for you)\n",
    "train_images_folder = fr\".\\auto_generated_dataset\\train_data\\images\"\n",
    "train_labels_folder = fr\".\\auto_generated_dataset\\train_data\\labels\"\n",
    "\n",
    "val_images_folder = fr\".\\auto_generated_dataset\\val_data\\images\"\n",
    "val_labels_folder = fr\".\\auto_generated_dataset\\val_data\\labels\"\n",
    "\n",
    "# size and train / test split\n",
    "num_images_to_generate = 12000\n",
    "train_split = 0.8\n",
    "val_split = 1 - train_split\n",
    "num_workers = 6 # adjust for you cpu\n",
    "num_workers -= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code is one of the worst creations humanity has yet seen in this programming language.\n",
    "# it was written as a one time use program that i kept upgrading without properly restructuring.\n",
    "# if anybody is brave enough to go into thjese functions and fix everything you are welcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_label(path, classes, bnd_boxes):\n",
    "    \"\"\"\n",
    "    generates a text file with the label information in the YOLO format.\n",
    "    exactly the way labelimg does it\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(path, \"w\") as file:\n",
    "        for current_class, current_bnd_box in zip(classes, bnd_boxes):\n",
    "            file.write(f\"{current_class} \")\n",
    "            \n",
    "            for current_coordinate in current_bnd_box:\n",
    "                file.write(f\"{current_coordinate:.6f} \")\n",
    "            \n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_img(img):\n",
    "    \"\"\"\n",
    "    this applies a swirl effect on the image, used on the enemy images to give more variaty\n",
    "    \"\"\"\n",
    "    warped_img = swirl(np.array(img), rotation=random.randint(-3, 3) / 16, strength=random.randint(-30, 30) / 50, radius=img.size[1])\n",
    "    warped_img = Image.fromarray(img_as_ubyte(warped_img))\n",
    "    \n",
    "    return warped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_random_color(original_img, max_intensity=0.1):\n",
    "    \"\"\"\n",
    "    overlays a random color over the whole image, max intensity controlls the transparency\n",
    "    \"\"\"\n",
    "    overlay = Image.new('RGBA', (1, 1), (random.randint(0, 255),\n",
    "                                         random.randint(0, 255),\n",
    "                                         random.randint(0, 255),\n",
    "                                         random.randint(0, int(255 * max_intensity))))\n",
    "    \n",
    "    return Image.alpha_composite(original_img.convert('RGBA'), overlay.resize(original_img.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img_size(original_img, long_side_size=640):\n",
    "    \"\"\"\n",
    "    makes it so no matter what, the long side of the image given is 640px\n",
    "    this is used because in the dataset materials, the enemy images have different sizes, so the network wont get used\n",
    "    to certain classes being naturally smaller than others\n",
    "    \"\"\"\n",
    "    new_width = long_side_size if original_img.size[0] >= original_img.size[1] else int(original_img.size[0] * (long_side_size / original_img.size[1]))\n",
    "    new_height = long_side_size if original_img.size[0] < original_img.size[1] else int(original_img.size[1] * (long_side_size / original_img.size[0]))\n",
    "    return original_img.resize((new_width, new_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paste_random_position(background_img, new_object_img, scale_variation=(0.1, 0.5), rotation_variation=(-25, 25)):\n",
    "    \"\"\"\n",
    "    self explanatory\n",
    "    \"\"\"\n",
    "    # apply transformations\n",
    "    new_object_img_size = new_object_img.size\n",
    "    \n",
    "    # note that the resize works independently on the x and y axis, so the image might be squished and streched\n",
    "    new_object_img = warp_img(new_object_img)\n",
    "    chosen_warp = random.randint(int(new_object_img_size[0] * scale_variation[0]), int(new_object_img_size[0] * scale_variation[1]))\n",
    "    new_object_img = new_object_img.resize((chosen_warp, int(chosen_warp * (random.randint(5, 15) / 10))))\n",
    "    \n",
    "    new_object_img = new_object_img.rotate(random.randint(*rotation_variation), expand=True)\n",
    "    \n",
    "    # measure the size again because the rotation changes it when expand==True (if its ==False then image will be cropped)\n",
    "    new_object_img_size = new_object_img.size\n",
    "    \n",
    "    # !!!THIS IS THE PART THAT DECIDES WHERE TO PASTE THE IMAGE!!!\n",
    "    max_start_x = max(background_img.size[0] - new_object_img_size[0], 0)\n",
    "    max_start_y = max(background_img.size[1] - new_object_img_size[1], 0)\n",
    "\n",
    "    # Update the paste positions to ensure the image fits within bounds\n",
    "    paste_start_x = random.randint(0, max_start_x)\n",
    "    paste_start_y = random.randint(0, max_start_y)\n",
    "    paste_end_x = paste_start_x + new_object_img_size[0]\n",
    "    paste_end_y = paste_start_y + new_object_img_size[1]\n",
    "    \n",
    "    # finally paste the image over the background\n",
    "    background_img.paste(new_object_img, (paste_start_x, paste_start_y), new_object_img)\n",
    "    \n",
    "    # convert from \"corners\" foramt to \"center + width/height\" format (also normalize)\n",
    "    bnd_box_center_x = (paste_start_x + paste_end_x) / 2 / background_img.size[0]\n",
    "    bnd_box_center_y = (paste_start_y + paste_end_y) / 2 / background_img.size[1]\n",
    "    bnd_box_width = (paste_end_x - paste_start_x) / background_img.size[0]\n",
    "    bnd_box_height = (paste_end_y - paste_start_y) / background_img.size[1]\n",
    "    \n",
    "    return bnd_box_center_x, bnd_box_center_y, bnd_box_width, bnd_box_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_obstruction(original_img, obstruction_img):\n",
    "    \"\"\"\n",
    "    overlays an image over another image, useful for overlaying a obstruction over an enemy image\n",
    "    \"\"\"\n",
    "    result_img = original_img.copy()\n",
    "    result_img.paste(obstruction_img.resize(original_img.size), (0, 0), obstruction_img.resize(original_img.size))\n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in the \"materials\" and uses them to make a randomly generated image along with its labels\n",
    "# num_of_enemies       =   randomly choose how many enemies to paste on the background\n",
    "# scale_variation      =   how much to warp the scale of each enemy\n",
    "# rotation variation   =   in degrees, how much to randomly rotate the enemies on the image\n",
    "def generate_image(backgrounds_path, enemies_path, obstructions_path, num_of_enemies = (0, 10), max_obstructions=2, max_false_obstructions=10):\n",
    "    \"\"\"\n",
    "    applies all of the functions above to return a finished product\n",
    "    \"\"\"\n",
    "    # define the \"answer\" tensors that will be used to train the net\n",
    "    enemy_bnd_boxes = []\n",
    "    enemy_classes = []\n",
    "    \n",
    "    # chosen_background_path is a path to an random image from the folder background_path\n",
    "    chosen_background_path = os.listdir(backgrounds_path)\n",
    "    obstruction_files = os.listdir(obstructions_path)\n",
    "    chosen_background_path = backgrounds_path + \"\\\\\" + chosen_background_path[random.randint(0, len(chosen_background_path) - 1)]\n",
    "    \n",
    "    # load the background to PIL (this image will be used as the foundation to paste other images on)\n",
    "    background_image = Image.open(chosen_background_path)\n",
    "    \n",
    "    chosen_num_of_enemies = random.randint(*num_of_enemies)\n",
    "    \n",
    "    # add random obstructions to the background\n",
    "    for _ in range(random.randint(0, max_false_obstructions)):\n",
    "        current_obstruction = obstruction_files[random.randint(0, len(obstruction_files) - 1)]\n",
    "        current_obstruction = obstructions_path + \"\\\\\" + current_obstruction\n",
    "        current_obstruction = Image.open(current_obstruction)\n",
    "        paste_random_position(background_image, current_obstruction)\n",
    "    \n",
    "    # add the enemies\n",
    "    for _ in range(chosen_num_of_enemies):\n",
    "        # choose what enemy image we will be overlaying now\n",
    "        enemy_folders = os.listdir(enemies_path)\n",
    "        chosen_enemy_class = random.randint(0, len(enemy_folders) - 1)\n",
    "        chosen_folder = enemies_path + \"\\\\\" + enemy_folders[chosen_enemy_class]\n",
    "        chosen_enemy_class = folder_class_priority.index(enemy_folders[chosen_enemy_class])\n",
    "        enemy_files = os.listdir(chosen_folder)\n",
    "        chosen_file = chosen_folder + \"\\\\\" + enemy_files[random.randint(0, len(enemy_files) - 1)]\n",
    "        \n",
    "        # load image that will be pasted\n",
    "        current_enemy_image = Image.open(chosen_file)\n",
    "        \n",
    "        # ensure consistent sizing across images with different resolutions\n",
    "        # make sure there is no warping using the original resolution of the image\n",
    "        current_enemy_image = normalize_img_size(current_enemy_image)\n",
    "        \n",
    "        # add a random number of random obstructions to each enemy\n",
    "        for _ in range(random.randint(0, max_obstructions)):\n",
    "            current_obstruction = random.randint(0, len(obstruction_files) - 1)\n",
    "            current_obstruction = obstructions_path + \"\\\\\" + obstruction_files[current_obstruction]\n",
    "            current_obstruction = Image.open(current_obstruction)\n",
    "            current_enemy_image = add_obstruction(current_enemy_image, current_obstruction)\n",
    "        \n",
    "        bnd_box_center_x, bnd_box_center_y, bnd_box_width, bnd_box_height = paste_random_position(background_image, current_enemy_image)\n",
    "        \n",
    "        enemy_bnd_boxes.append([bnd_box_center_x, bnd_box_center_y, bnd_box_width, bnd_box_height])\n",
    "        enemy_classes.append(chosen_enemy_class)\n",
    "    \n",
    "    background_image = overlay_random_color(background_image)\n",
    "    \n",
    "    return background_image, enemy_bnd_boxes, enemy_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"main\" function that generates a dataset from \"materials\" given to it\n",
    "def generate_dataset(backgrounds_path, objects_path, images_path, labels_path, dataset_size, start_idx):\n",
    "    \"\"\"\n",
    "    runs the function above a certain number of times\n",
    "    \"\"\"\n",
    "    \n",
    "    for x in range(dataset_size):\n",
    "        current_name = f\"auto_generated_train_{x + start_idx}\"\n",
    "        \n",
    "        generated_image, bnd_boxes, classes = generate_image(backgrounds_path, objects_path, obstructions_path)\n",
    "        \n",
    "        generated_image.save(os.path.join(images_path, current_name + \".png\"), \"png\")\n",
    "        \n",
    "        write_label(os.path.join(labels_path, current_name + \".txt\"), classes, bnd_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_workers(backgrounds_path, objects_path, images_path, labels_path, dataset_size, num_workers):\n",
    "    \"\"\"\n",
    "    this is to speed up the process (utilize 130% of your cpu)\n",
    "    \"\"\"\n",
    "    \n",
    "    individual_tasks = int(dataset_size / num_workers)\n",
    "    worker_threads = []\n",
    "    \n",
    "    for current_worker in range(num_workers):\n",
    "        worker_thread = threading.Thread(target=generate_dataset, args=(backgrounds_path, objects_path, images_path, labels_path, individual_tasks, current_worker * individual_tasks))\n",
    "        worker_threads.append(worker_thread)\n",
    "    \n",
    "    return worker_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_files():\n",
    "    # make sure that the folder structure is actually there\n",
    "    os.makedirs(train_images_folder, exist_ok=True)\n",
    "    os.makedirs(val_images_folder, exist_ok=True)\n",
    "    os.makedirs(train_labels_folder, exist_ok=True)\n",
    "    os.makedirs(val_labels_folder, exist_ok=True)\n",
    "\n",
    "    if not (os.path.exists(backgrounds_path) and os.path.exists(objects_path) and os.path.exists(obstructions_path)):\n",
    "        print(\"the thing does not exist. please put the materials thing into the same directory as this file.\")\n",
    "    else:\n",
    "        print(\"everything seems to be set up. check_files() is paying for you before you start the threads 🙏\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything seems to be set up. check_files() is paying for you before you start the threads 🙏\n"
     ]
    }
   ],
   "source": [
    "check_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_threads = create_workers(backgrounds_path, objects_path, train_images_folder, train_labels_folder,\n",
    "                               int(num_images_to_generate * train_split), # dataset size\n",
    "                               1 + int(train_split * num_workers)) # workers for this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_threads = create_workers(backgrounds_path, objects_path, val_images_folder, val_labels_folder,\n",
    "                             int(num_images_to_generate * val_split), # dataset size\n",
    "                             1 + int(val_split * num_workers)) # workers for this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 3999.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started train dataset generation threads succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started val dataset generation threads succesfully\n",
      "you will know when the threads finish working when CPU utilization goes back to normal (look at task manager)\n",
      "if you want to stop the threads prematurly then either restart runtime, or kill all python processes also from task manager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm(train_threads):\n",
    "    x.start()\n",
    "\n",
    "print(\"started train dataset generation threads succesfully\")\n",
    "\n",
    "for x in tqdm(val_threads):\n",
    "    x.start()\n",
    "\n",
    "print(\"started val dataset generation threads succesfully\")\n",
    "\n",
    "print(\"you will know when the threads finish working when CPU utilization goes back to normal (look at task manager)\")\n",
    "print(\"if you want to stop the threads prematurly then either restart runtime, or kill all python processes also from task manager\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python train.py --img 1024 --batch 5 --data dataset.yaml --workers 6 --weights [PATH/TO/YOLOV5/REPO]\\\\yolov5\\\\yolov5m.pt --epochs 80'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after all that finished running clone the YOLOv5 repository, configure everything following this tutorial:\n",
    "# https://www.youtube.com/watch?v=tFNJGim3FXw&t=3516s\n",
    "# this is the training command that worked fine on RTX2060 6GB vram, adjust batches for your GPU\n",
    "\n",
    "r\"\"\"\n",
    "python train.py\n",
    "--img 1024\n",
    "--batch 5\n",
    "--data dataset.yaml\n",
    "--workers 6\n",
    "--weights [PATH/TO/YOLOV5/REPO]\\yolov5\\yolov5m.pt\n",
    "--epochs 80\n",
    "\"\"\".replace(\"\\n\", \" \")[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAIN_CONDA_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
